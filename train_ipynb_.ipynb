{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEvyW0lg56U"
      },
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Dropout,Embedding,CuDNNLSTM,Bidirectional\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import concatenate, SpatialDropout1D\n",
        "from keras.layers.core import  Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import tqdm\n",
        "from keras.layers import Attention\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.layers import Lambda\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3T0zljg9KR"
      },
      "source": [
        "#Считываю сохраненный датафрейм\n",
        "f=open('/content/data.csv')\n",
        "data=pd.read_csv(f)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkM1zD8MhNdX"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xkG7Itrqa5W"
      },
      "source": [
        "#Добавляю в начало и конец каждого названия подборки begin и end что бы затем   \n",
        "data['title'] = data['title'].apply(lambda x: 'begin ' + x \\\n",
        "        + ' end')\n"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo_LGTB-hJht"
      },
      "source": [
        "#Разделяю данные на тренеровочные и валидационные данные\n",
        "train_text, test_text, train_y, test_y = train_test_split(data['headline'],data['title'],test_size = 0.4,random_state=42)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxtVh05fhUpb"
      },
      "source": [
        "max_len_text=100\n",
        "max_len_summary=20"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voMN8wjDhctN"
      },
      "source": [
        "#Создаю токинайзеры , убираю из тексата символы\n",
        "x_tokenizer=Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True)\n",
        "x_tokenizer.fit_on_texts(list(train_text))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "train_text    =   x_tokenizer.texts_to_sequences(train_text) \n",
        "test_text   =   x_tokenizer.texts_to_sequences(test_text)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "train_x    =   pad_sequences(train_text,  maxlen=max_len_text, padding='post') \n",
        "test_x   =   pad_sequences(test_text, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxzMLjZfhfue"
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True)\n",
        "y_tokenizer.fit_on_texts(list(train_y))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "train_y    =   y_tokenizer.texts_to_sequences(train_y) \n",
        "test_y   =   y_tokenizer.texts_to_sequences(test_y) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "train_y    =   pad_sequences(train_y, maxlen=max_len_summary, padding='post')\n",
        "test_y   =   pad_sequences(test_y, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5BSPlx1jNNK"
      },
      "source": [
        "x_tr = pad_sequences(train_x,  maxlen=max_len_text, padding='post')\n",
        "x_val = pad_sequences(test_x, maxlen=max_len_text, padding='post')\n",
        "y_tr = pad_sequences(train_y, maxlen=max_len_summary, padding='post')\n",
        "y_val = pad_sequences(test_y, maxlen=max_len_summary, padding='post')\n"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lklvazFSE50",
        "outputId": "560f9bcb-ee93-472b-d76b-bdded506ecfe"
      },
      "source": [
        "type(x_tr[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_SPMwgZi-su"
      },
      "source": [
        "latent_dim = 300\n",
        "embedding_dim = 200\n",
        "\n",
        "\n",
        "encoder_inputs = Input(shape=(max_len_text, ))\n",
        "\n",
        "enc_emb = Embedding(x_voc_size, embedding_dim,\n",
        "                    trainable=True)(encoder_inputs)\n",
        "\n",
        "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
        "                     return_state=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "\n",
        "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
        "\n",
        "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
        "                     return_state=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
        "\n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
        "                     return_sequences=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
        "\n",
        "\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "\n",
        "dec_emb_layer = Embedding(y_voc_size, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
        "                    return_state=True, dropout=0.4,\n",
        "                    recurrent_dropout=0.2)\n",
        "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
        "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHIYy00IgIxo"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Xo3L2WkOAs"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK_cYbO6r1RM"
      },
      "source": [
        "for i in range (15):\n",
        "\n",
        "    history = model.fit(\n",
        "    [x_tr, y_tr[:, :-1]],\n",
        "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
        "    epochs=5,\n",
        "    batch_size=20,\n",
        "    validation_data=([x_val, y_val[:, :-1]],\n",
        "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
        "                     , 1:]),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dClNyZV1mY6J"
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index\n"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdd4u_K9pAVm"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
        "                      state_h, state_c])\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_hidden_state_input = Input(shape=(100, latent_dim))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Fu7TlJoLIR"
      },
      "source": [
        "#создает тему для этих заголовков\n",
        "def decode_sequence(input_seq):\n",
        "\n",
        "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "\n",
        "    target_seq[0, 0] = target_word_index['begin']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if sampled_token != 'end':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        if sampled_token == 'end' or len(decoded_sentence.split()) \\\n",
        "            >= 12 - 1:\n",
        "            stop_condition = True\n",
        "\n",
        "        \n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cET5O8jmC76"
      },
      "source": [
        "# превращает последовательность цифр в название подборки\n",
        "def seq2summary(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != target_word_index['begin'] and i \\\n",
        "            != target_word_index['end']:\n",
        "            newString = newString + reverse_target_word_index[i] + ' '\n",
        "\n",
        "    return newString"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmw7PeE8mFh3"
      },
      "source": [
        "# Преврашает последовательность цифр в тексты заголовков\n",
        "def seq2text(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0:\n",
        "            newString = newString + reverse_source_word_index[i] + ' '\n",
        "\n",
        "    return newString"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zz-gUumHmh"
      },
      "source": [
        "for i in range(0,20):\n",
        "    print ('Заголовки:', seq2text(x_tr[i]))\n",
        "    print ('Оригинальное название подборки:', seq2summary(y_tr[i]))\n",
        "    print ('Сгенерированное название подборки:', decode_sequence(x_tr[i].reshape(1,100)))\n",
        "    print ('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2uvfL1M6qZI",
        "outputId": "105f4c17-503a-4e68-8c72-b2ae0cf9c9a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnTulSIM5F9j",
        "outputId": "9ff42292-403e-4c4d-8354-2541e1b0936a"
      },
      "source": [
        "model.save('/content/drive/My Drive/model1/')"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/model1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp33hYYY5My-",
        "outputId": "0880c660-d771-4347-9978-02f023da41a1"
      },
      "source": [
        "decoder_model.save('/content/drive/My Drive/decoder_model/')\n",
        "encoder_model.save('/content/drive/My Drive/encoder_model/')"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/decoder_model/assets\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/encoder_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7W79TW27OsX"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('x_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsxhtQho9Xjh"
      },
      "source": [
        "# saving\n",
        "with open('y_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 237,
      "outputs": []
    }
  ]
}